{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Overview\n",
    "\n",
    "#### Objective: Move the CSVs into a denormalized Apache Cassandra database that we can run queries on.\n",
    "\n",
    "##### Steps\n",
    "###### Step 1: Process the CSVs into a single data file\n",
    "###### Step 2: Create Apache Cassandra cluster and keyspace.\n",
    "###### Step 3: Model the database.\n",
    "###### Step 4: Build ETL pipeline.\n",
    "###### Step 5: \n",
    "\n",
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## PLEASE RUN THE FOLLOWING CODE FOR PRE-PROCESSING THE FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import Python packages \n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory : /home/workspace\n",
      "['/home/workspace/event_data/2018-11-27-events.csv', '/home/workspace/event_data/2018-11-04-events.csv', '/home/workspace/event_data/2018-11-07-events.csv', '/home/workspace/event_data/2018-11-09-events.csv', '/home/workspace/event_data/2018-11-19-events.csv', '/home/workspace/event_data/2018-11-05-events.csv', '/home/workspace/event_data/2018-11-22-events.csv', '/home/workspace/event_data/2018-11-16-events.csv', '/home/workspace/event_data/2018-11-26-events.csv', '/home/workspace/event_data/2018-11-24-events.csv', '/home/workspace/event_data/2018-11-29-events.csv', '/home/workspace/event_data/2018-11-15-events.csv', '/home/workspace/event_data/2018-11-20-events.csv', '/home/workspace/event_data/2018-11-06-events.csv', '/home/workspace/event_data/2018-11-18-events.csv', '/home/workspace/event_data/2018-11-21-events.csv', '/home/workspace/event_data/2018-11-10-events.csv', '/home/workspace/event_data/2018-11-23-events.csv', '/home/workspace/event_data/2018-11-02-events.csv', '/home/workspace/event_data/2018-11-28-events.csv', '/home/workspace/event_data/2018-11-03-events.csv', '/home/workspace/event_data/2018-11-13-events.csv', '/home/workspace/event_data/2018-11-30-events.csv', '/home/workspace/event_data/2018-11-12-events.csv', '/home/workspace/event_data/2018-11-01-events.csv', '/home/workspace/event_data/2018-11-14-events.csv', '/home/workspace/event_data/2018-11-25-events.csv', '/home/workspace/event_data/2018-11-08-events.csv', '/home/workspace/event_data/2018-11-17-events.csv', '/home/workspace/event_data/2018-11-11-events.csv']\n"
     ]
    }
   ],
   "source": [
    "# checking your current working directory\n",
    "print(f\"Current working directory : {os.getcwd()}\") # Added f string, Current working directory to make steps more clear\n",
    "\n",
    "# Create a filepath variable composed of your current folder/working directory and subfolder event data\n",
    "# Note that os.walk returns a generator, that creates a tuple of values (current_path, \\\n",
    "# directories in current_path, files in current_path)\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# Create a for loop using os.walk to literally walk through that directory structure to \\\n",
    "# 1 - create a list of files/tuple of values and 2 - collect each filepath for eventual integration\n",
    "# A root is the highest directory in the filepath, e.g. C:\\\n",
    "# A directory is the folder holding the file, e.g. C:\\kgwhite2\\Documents\\Taxes\n",
    "# A file is the resource for recording data, e.g. C:\\kgwhite2\\Documents\\Taxes\\2020return.pdf\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    \n",
    "# join the file paths (files) and roots (root) into 1 variable with the subdirectories (dir) using glob\n",
    "# glob is a Python module that's useful whenever we need to look for a list of files with names matching a pattern\n",
    "# With glob, I can scan a directory for any file that has a certain extension, prefix or comon string in the middle\n",
    "    file_path_list = glob.glob(os.path.join(root,'*')) # glob creates a list of filepaths to process all event_data\n",
    "    print(file_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows : 8056\n",
      "Sample data:\n",
      " [['Barry Tuckwell/Academy of St Martin-in-the-Fields/Sir Neville Marriner', 'Logged In', 'Mohammad', 'M', '0', 'Rodriguez', '277.15873', 'paid', 'Sacramento--Roseville--Arden-Arcade, CA', 'PUT', 'NextSong', '1.54051E+12', '961', 'Horn Concerto No. 4 in E flat K495: II. Romance (Andante cantabile)', '200', '1.54328E+12', '88'], ['Jimi Hendrix', 'Logged In', 'Mohammad', 'M', '1', 'Rodriguez', '239.82975', 'paid', 'Sacramento--Roseville--Arden-Arcade, CA', 'PUT', 'NextSong', '1.54051E+12', '961', 'Woodstock Inprovisation', '200', '1.54328E+12', '88'], ['Building 429', 'Logged In', 'Mohammad', 'M', '2', 'Rodriguez', '300.61669', 'paid', 'Sacramento--Roseville--Arden-Arcade, CA', 'PUT', 'NextSong', '1.54051E+12', '961', 'Majesty (LP Version)', '200', '1.54328E+12', '88'], [\"The B-52's\", 'Logged In', 'Gianna', 'F', '0', 'Jones', '321.54077', 'free', 'New York-Newark-Jersey City, NY-NJ-PA', 'PUT', 'NextSong', '1.54087E+12', '107', 'Love Shack', '200', '1.54328E+12', '38'], ['Die Mooskirchner', 'Logged In', 'Gianna', 'F', '1', 'Jones', '169.29914', 'free', 'New York-Newark-Jersey City, NY-NJ-PA', 'PUT', 'NextSong', '1.54087E+12', '107', \"Frisch und g'sund\", '200', '1.54328E+12', '38']]\n"
     ]
    }
   ],
   "source": [
    "# Create/Initiate an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# loop through every filepath in the filepath list (created in the glob step)\n",
    "for f in file_path_list:\n",
    "\n",
    "# Read each csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # creating a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)\n",
    "        \n",
    "# Extract data from each row one by one and append it to the empty list of rows \\\n",
    "# (created in the full_data_rows_list =[] step)       \n",
    "        for line in csvreader:\n",
    "            #print(line)\n",
    "            full_data_rows_list.append(line) \n",
    "            \n",
    "# The code below gets the total number of rows. I added an F string to form a sentence with it. \n",
    "print(f\"Total rows : {len(full_data_rows_list)}\")\n",
    "# The code below gets what the list of event data rows will look like. I added an F string to form a sentence with it. \n",
    "print(f\"Sample data:\\n {full_data_rows_list[:5]}\")\n",
    "\n",
    "\n",
    "# I will now create a smaller event data csv file called event_datafile_full csv that \\\n",
    "# will be used to insert data into the Apache Cassandra tables\n",
    "# csv.register_dialect creates a new dialect that specifies the CSV file's delimiter and other parameters\n",
    "# csv.register_dialect(name, formattingparameters) is the common format\n",
    "# It can be erased with csv.unregister_dialect(name)\n",
    "# We name our new dialect 'myDialect'\n",
    "# The quoting=csv.QUOTE_ALL formatting parameter quotes (includes?) everything, regardless of type\n",
    "# The skipinitialspace=True formatting parameter controls how the space following the delimiter will be interpreted. \n",
    "# E.g. If True, the initial whitespaces will be removed. In [\"Adam Donachie\", \"BAL\"], the whitespace is ignored. False is the default value.\n",
    "# For more learning, look into Python CSV package tutorials on thepythonguru.com\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    #using the dialect created above, create the smaller event_data csv file\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n",
    "\n",
    "# I've now completed Step 1 and processed these data into a single data file /\n",
    "# to move into the Apache Cassandra database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6821\n"
     ]
    }
   ],
   "source": [
    "# check the number of rows in your csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Part II. Complete the Apache Cassandra coding portion of your project. \n",
    "\n",
    "## Now you are ready to work with the CSV file titled <font color=red>event_datafile_new.csv</font>, located within the Workspace directory.  The event_datafile_new.csv contains the following columns: \n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n",
    "\n",
    "The image below is a screenshot of what the denormalized data should appear like in the <font color=red>**event_datafile_new.csv**</font> after the code above is run:<br>\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Begin writing your Apache Cassandra code in the cells below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection Established !!\n"
     ]
    }
   ],
   "source": [
    "# This should make a connection to a Cassandra instance your local machine \n",
    "# (127.0.0.1)\n",
    "\n",
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster()\n",
    "\n",
    "try:\n",
    "    cluster = Cluster(['127.0.0.1'])\n",
    "    session = cluster.connect()\n",
    "    print(\"Connection Established !!\")\n",
    "except Exception as e:\n",
    "    print(f\"Connection Failed !! Error : {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create Keyspace\n",
    "##### In a relational data model, this would be a database. In Cassandra, databases are known as keyspaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TO-DO: Create a Keyspace \n",
    "\n",
    "# Create the sparkify keyspace\n",
    "keyspace_query = \"\"\"CREATE KEYSPACE IF NOT EXISTS sparkify \n",
    "                    with REPLICATION = \n",
    "                    { 'class' : 'SimpleStrategy', 'replication_factor' : 1 }\n",
    "                \"\"\"\n",
    "\n",
    "try:\n",
    "    session.execute(keyspace_query)\n",
    "except Exception as e:\n",
    "    print(f\"Failed to create keyspace!! Error : {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TO-DO: Set KEYSPACE to the keyspace specified above\n",
    "\n",
    "session.set_keyspace('sparkify')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Now we need to create tables to run the following queries. Remember, with Apache Cassandra you model the database tables on the queries you want to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Create queries to ask the following three questions of the data\n",
    "\n",
    "### 1. Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "\n",
    "\n",
    "### 2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "    \n",
    "\n",
    "### 3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "====================================================================================================================================\n",
    "\n",
    "## Query 1\n",
    "\n",
    "#### Remember, with Apache Cassandra, we model the database tables on the queries we want to run!\n",
    "#### For Query 1, we'll A) create a table and B) run a query that selects the 1) artist name, 2) song name, and 3) song length from the table, while filtering by 4) sessionId and 5) itemInSession.\n",
    "\n",
    "   > * Create table with 5 columns of 1) artist name, 2) song name, and 3) song length 4) sessionId and 5) itemInSession from the single data file we created above\n",
    "   > * Run SQL query filtering the table by sessionId = 338 and itemInSession = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Created!!\n"
     ]
    }
   ],
   "source": [
    "## TO-DO: Query 1:  Give me the artist, song title and song's length in the music app history that was heard during \\\n",
    "## sessionId = 338, and itemInSession = 4\n",
    "\n",
    "## We 1) create the table that the query runs off of, 2) then we run the query\n",
    "## 1) Create the Table\n",
    "## Include: 1) naming the table (session_ken), 2) defining the columns with data type, 3) setting a primary key, \\\n",
    "## and 4) setting a clustering key\n",
    "## The primary key is known as a partition key in Cassandra. The primary key is a special relational database table \\\n",
    "## column (or combination of columns) designated to uniquely identify each table record.\n",
    "## The Cassandra clustering keys are the other fields we'll use to filter results by. This approach is unique to \\\n",
    "## Cassandra and is tied to how in Cassandra, we must model the database tables on the queries we want to run!\n",
    "\n",
    "createtable_query1 = \"\"\"CREATE TABLE IF NOT EXISTS session_ken (artist text, song text, length float, sessionId int,\n",
    "itemInSession int, PRIMARY KEY (sessionId, itemInSession))\"\"\"\n",
    "\n",
    "try: \n",
    "    session.execute(createtable_query1)\n",
    "    print(\"Table Created!!\")\n",
    "except Exception as e:\n",
    "    print(f\"Table creation failed!! Error : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# We have provided part of the code to set up the CSV file. Please complete the Apache Cassandra code below#\n",
    "# Define the file we want to use for uploading data into the 'session_ken' columnfamily, which is called a table \\\n",
    "# in a relational data model\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "# We'll read the CSV event file and insert rows into the session_ken table\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "## TO-DO: Assign the INSERT statements into the `query` variable\n",
    "## ?\n",
    "        query = \"INSERT INTO session_ken (artist, song, length, sessionId, itemInSession)\" \n",
    "        query = query + \"VALUES (%s, %s, %s, %s, %s)\"\n",
    "        ## TO-DO: Assign which column element should be assigned for each column in the INSERT statement.\n",
    "        ## For e.g., to INSERT artist_name and user first_name, you would change the code below to `line[0], line[1]`\n",
    "        session.execute(query, (line[0], line[10], float(line[5]), int(line[8]), int(line[3])) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Do a SELECT to verify that the data have been inserted into each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(artist='Faithless', song='50', length=495.30731201171875)\n"
     ]
    }
   ],
   "source": [
    "## TO-DO: Add in the SELECT statement to verify the data was entered into the table\n",
    "## ?\n",
    "\n",
    "select_query1 = \"SELECT artist, song, length FROM  session_ken where sessionId = 338 and itemInSession = 4\"\n",
    "try:\n",
    "    rows = session.execute(select_query1)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### COPY AND REPEAT THE ABOVE THREE CELLS FOR EACH OF THE THREE QUESTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Created!!\n"
     ]
    }
   ],
   "source": [
    "## TO-DO: Query 2: Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name)\\\n",
    "## for userid = 10, sessionid = 182\n",
    "\n",
    "## ?\n",
    "create_query2 = \"\"\"CREATE TABLE IF NOT EXISTS user_session (sessionId int, userId int, artist text, \n",
    "song text, firstName text, lastName text, itemInSession int, PRIMARY KEY ((sessionId, userId), \n",
    "itemInSession)) WITH CLUSTERING ORDER BY (itemInSession ASC) \"\"\"\n",
    "\n",
    "try: \n",
    "    session.execute(create_query2)\n",
    "    print(\"Table Created!!\")\n",
    "except Exception as e:\n",
    "    print(f\"Table creation failed!! Error : {e}\")\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## ?\n",
    "\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO user_session (sessionId, userId, artist, song, firstName, lastName, itemInSession) \"\n",
    "        query = query + \" VALUES (%s, %s, %s, %s, %s, %s, %s) \"\n",
    "        session.execute(query, (int(line[8]), int(line[10]), line[0], line[9], line[1], line[4], int(line[3])  ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(artist='Down To The Bone', song=\"Keep On Keepin' On\", firstname='Sylvie', lastname='Cruz')\n",
      "Row(artist='Three Drives', song='Greece 2000', firstname='Sylvie', lastname='Cruz')\n",
      "Row(artist='Sebastien Tellier', song='Kilometer', firstname='Sylvie', lastname='Cruz')\n",
      "Row(artist='Lonnie Gordon', song='Catch You Baby (Steve Pitron & Max Sanna Radio Edit)', firstname='Sylvie', lastname='Cruz')\n"
     ]
    }
   ],
   "source": [
    "# SELECT statement to verify the data was entered into the table\n",
    "## ?\n",
    "\n",
    "select_query2 = \"SELECT artist, song, firstName, lastName FROM  user_session where sessionId = 182 and userId = 10\"\n",
    "try:\n",
    "    rows = session.execute(select_query2)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Created!!\n"
     ]
    }
   ],
   "source": [
    "## TO-DO: Query 3: Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "## ?\n",
    "\n",
    "create_query3 = \"\"\"CREATE TABLE IF NOT EXISTS user_song_ken (song text, userId int, firstName text, lastName text, PRIMARY KEY ((song), userId))\"\"\"\n",
    "\n",
    "try: \n",
    "    session.execute(create_query3)\n",
    "    print(\"Table Created!!\")\n",
    "except Exception as e:\n",
    "    print(f\"Table creation failed!! Error : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## ?\n",
    "\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO user_song_ken (song, userId, firstName, lastName) \"\n",
    "        query = query + \" VALUES (%s, %s, %s, %s) \"\n",
    "        session.execute(query, (  line[9], int(line[10]), line[1], line[4] )  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(song='All Hands Against His Own', firstname='Jacqueline', lastname='Lynch')\n",
      "Row(song='All Hands Against His Own', firstname='Tegan', lastname='Levine')\n",
      "Row(song='All Hands Against His Own', firstname='Sara', lastname='Johnson')\n"
     ]
    }
   ],
   "source": [
    "# SELECT statement to verify the data was entered into the table\n",
    "## SEE OTHER NOTES!\n",
    "\n",
    "select_query3 = \"SELECT song, firstName, lastName FROM user_song_ken where song = 'All Hands Against His Own'\"\n",
    "try:\n",
    "    rows = session.execute(select_query3)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7fa1583f5da0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TO-DO: Drop the table before closing out the sessions\n",
    "session.execute(\"DROP TABLE IF EXISTS sparkify.session_ken\")\n",
    "session.execute(\"DROP TABLE IF EXISTS sparkify.user_session\")\n",
    "session.execute(\"DROP TABLE IF EXISTS sparkify.user_song_ken\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Close the session and cluster connection¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
